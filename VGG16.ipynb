{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malibio/project-1-deep-learning-image-classification-via-cnn/blob/main/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ba97da7",
      "metadata": {
        "id": "2ba97da7"
      },
      "source": [
        "Global imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f7ab67c6",
      "metadata": {
        "id": "f7ab67c6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import time\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "302577d3",
      "metadata": {
        "id": "302577d3"
      },
      "source": [
        "Load CIFAR-10 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "caf57240",
      "metadata": {
        "id": "caf57240"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.1),\n",
        "    RandomZoom(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "gblkksCbkAPO"
      },
      "id": "gblkksCbkAPO",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a9bfed05",
      "metadata": {
        "id": "a9bfed05"
      },
      "source": [
        "Normalize the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9a452db9",
      "metadata": {
        "id": "9a452db9"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c14b8e5",
      "metadata": {
        "id": "8c14b8e5"
      },
      "source": [
        "Convert Labels to One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a9bdcc00",
      "metadata": {
        "id": "a9bdcc00"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcfe021c",
      "metadata": {
        "id": "dcfe021c"
      },
      "source": [
        "Split Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0b9a5a28",
      "metadata": {
        "id": "0b9a5a28"
      },
      "outputs": [],
      "source": [
        "validation_split = 0.2\n",
        "num_train_samples = int((1 - validation_split) * x_train.shape[0])\n",
        "x_train_final = x_train[:num_train_samples]\n",
        "y_train_final = y_train[:num_train_samples]\n",
        "x_val = x_train[num_train_samples:]\n",
        "y_val = y_train[num_train_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9af0bb06",
      "metadata": {
        "id": "9af0bb06"
      },
      "source": [
        " Resize Images to 224x224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1d392fea",
      "metadata": {
        "id": "1d392fea"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb601bcd",
      "metadata": {
        "id": "eb601bcd"
      },
      "source": [
        " Image Preprocessing Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "622c8da9",
      "metadata": {
        "id": "622c8da9"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = preprocess_input(image)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6388918",
      "metadata": {
        "id": "d6388918"
      },
      "source": [
        "Build Efficient Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4ceb278f",
      "metadata": {
        "id": "4ceb278f"
      },
      "outputs": [],
      "source": [
        "#Train\n",
        "batch_size = 64\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_final, y_train_final))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
        "train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "#validation\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "#test\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "4fc7a5f9",
      "metadata": {
        "id": "4fc7a5f9"
      },
      "outputs": [],
      "source": [
        "vgg16_base = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "vgg16_base.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WMPKlhGVqvrH"
      },
      "id": "WMPKlhGVqvrH"
    },
    {
      "cell_type": "markdown",
      "id": "09cd3976",
      "metadata": {
        "id": "09cd3976"
      },
      "source": [
        "Build Our Own Model on Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0dc2ef03",
      "metadata": {
        "id": "0dc2ef03",
        "outputId": "2e3594ed-d4c6-42b7-9db4-587d52a1038f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,114,314\u001b[0m (57.66 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,114,314</span> (57.66 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,477,514\u001b[0m (28.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,477,514</span> (28.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,636,800\u001b[0m (29.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,636,800</span> (29.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Base model - place this right after your IMG_SIZE definition\n",
        "vgg16_base = VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        ")\n",
        "\n",
        "# Fine-tuning setup - add this right after base model definition\n",
        "vgg16_base.trainable = True\n",
        "fine_tune_at = 15  # Fine-tune from this layer onwards\n",
        "for layer in vgg16_base.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Model construction - replace your current model building code\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = vgg16_base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)  # Better than Flatten\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f842d627",
      "metadata": {
        "id": "f842d627"
      },
      "source": [
        "Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c27b597c",
      "metadata": {
        "id": "c27b597c"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate = 0.0001  # Lower for fine-tuning\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82808d12",
      "metadata": {
        "id": "82808d12"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "9ce182b0",
      "metadata": {
        "id": "9ce182b0"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_vgg16_model.keras', monitor='val_accuracy', save_best_only=True, mode='max'),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18b4ea8",
      "metadata": {
        "id": "d18b4ea8",
        "outputId": "bb56c28f-be0c-46ab-e85d-71c9c993277e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14814070",
      "metadata": {
        "id": "14814070"
      },
      "source": [
        "Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce146b3",
      "metadata": {
        "id": "3ce146b3"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226976cd",
      "metadata": {
        "id": "226976cd"
      },
      "source": [
        "Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f907e34",
      "metadata": {
        "id": "0f907e34"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_dataset.take(1):\n",
        "    predictions = model.predict(images[:3])\n",
        "    print(predictions)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}