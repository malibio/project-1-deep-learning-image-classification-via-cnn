{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a680d824",
      "metadata": {
        "id": "a680d824"
      },
      "source": [
        "### Make the necessary imports (libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abe186c",
      "metadata": {
        "id": "5abe186c"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras as k\n",
        "\n",
        "from keras import layers, models, optimizers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.utils import to_categorical\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import tarfile\n",
        "import pickle\n",
        "import gzip\n",
        "import requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EEFXQXvssUV1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "EEFXQXvssUV1",
        "outputId": "696a1331-b5f0-48cc-b155-81eb3998d080"
      },
      "outputs": [],
      "source": [
        "def download_cifar10():\n",
        "  working_path = os.getcwd()\n",
        "  cifar_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "  file_name_gz = \"cifar-10-python.tar.gz\"\n",
        "  file_name_tar = \"cifar-10-python.tar\"\n",
        "\n",
        "  file_path_gz = os.path.join(working_path, file_name_gz)\n",
        "  file_path_tar = os.path.join(working_path, file_name_tar)\n",
        "\n",
        "  if os.path.exists(file_path_tar):\n",
        "      print(\"The file cifar-10-python.tar already exists\")\n",
        "  else:\n",
        "      print(\"Downloading CIFAR-10 data...\")\n",
        "      response = requests.get(cifar_url, stream=True)\n",
        "      response.raise_for_status()\n",
        "      with open(file_path_gz, 'wb') as f:\n",
        "          for chunk in response.iter_content(chunk_size=8192):\n",
        "              if chunk:\n",
        "                  f.write(chunk)\n",
        "\n",
        "      with gzip.open(file_path_gz, 'rb') as f_in:\n",
        "          with open(file_path_tar, 'wb') as f_out:\n",
        "              for chunk in f_in:\n",
        "                  f_out.write(chunk)\n",
        "      print\n",
        "  return file_path_tar\n",
        "\n",
        "download_cifar10()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43599bbb",
      "metadata": {
        "id": "43599bbb"
      },
      "source": [
        "### Load the data from a tar file (using pickle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77831e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77831e4",
        "outputId": "9c07459b-9c35-4ee1-d33b-962860d6d5a6"
      },
      "outputs": [],
      "source": [
        "def load_pickle_from_tar(tar_path, pickle_path):\n",
        "    with tarfile.open(tar_path, 'r') as tar:\n",
        "        member = tar.getmember(pickle_path)\n",
        "        f = tar.extractfile(member)\n",
        "        data_dict = pickle.load(f, encoding='bytes')\n",
        "    return data_dict\n",
        "\n",
        "# Set your tar_path to the file in the same working folder\n",
        "tar_path = \"cifar-10-python.tar\"  # File in the same working directory\n",
        "\n",
        "# Load training data\n",
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "print(\"Loading training data...\")\n",
        "# The path structure below is based on the standard CIFAR-10 distribution\n",
        "for i in range(1, 6):\n",
        "    batch_path = f'cifar-10-batches-py/data_batch_{i}'\n",
        "    print(f\"Loading batch {i}...\")\n",
        "    batch_dict = load_pickle_from_tar(tar_path, batch_path)\n",
        "    train_data.append(batch_dict[b'data'])\n",
        "    train_labels.extend(batch_dict[b'labels'])\n",
        "\n",
        "train_data = np.vstack(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ba80d8",
      "metadata": {
        "id": "05ba80d8"
      },
      "source": [
        "### Load the training/test data set and label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5c3162",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a5c3162",
        "outputId": "7658e384-6081-4c65-9a67-cf9b89360988"
      },
      "outputs": [],
      "source": [
        "print(\"Loading test data...\")\n",
        "test_batch_path = 'cifar-10-batches-py/test_batch'\n",
        "test_dict = load_pickle_from_tar(tar_path, test_batch_path)\n",
        "test_data = test_dict[b'data']\n",
        "test_labels = test_dict[b'labels']\n",
        "\n",
        "# Load label names\n",
        "print(\"Loading label names...\")\n",
        "meta_path = 'cifar-10-batches-py/batches.meta'\n",
        "meta_dict = load_pickle_from_tar(tar_path, meta_path)\n",
        "label_names = [label.decode('utf-8') for label in meta_dict[b'label_names']]\n",
        "\n",
        "# Print basic info about the data\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(f\"Label names: {label_names}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b437380",
      "metadata": {
        "id": "2b437380"
      },
      "source": [
        "### Reshape the data to match the expected input format for CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e9b1ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25e9b1ad",
        "outputId": "14465ed1-ab6d-448e-dfc6-69b42b9a1d83"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Each image is 32x32 pixels with 3 color channels (RGB)\n",
        "X_train = train_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reshape to (N, 32, 32, 3)\n",
        "X_test = test_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reshape to (N, 32, 32, 3)\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# Print updated shapes\n",
        "print(\"Training data shape after reshaping:\", X_train.shape)\n",
        "print(\"Test data shape after reshaping:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f03a3395",
      "metadata": {
        "id": "f03a3395"
      },
      "source": [
        "### Conduct preprocessing of the data:\n",
        "- Normalization (from 255 to 0/1)\n",
        "- Convert class vectors to binary class matices (via one-hot encoding)\n",
        "- Create validation data set (of 10% of training data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80310560",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80310560",
        "outputId": "45d6f8e1-b25d-4f9a-d6ac-4cfee355e792"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "def preprocess_data(X_train, y_train, X_test, y_test):\n",
        "    # Normalize pixel values to be between 0 and 1\n",
        "    X_train = X_train.astype('float32') / 255.0\n",
        "    X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "    # Convert class vectors to binary class matrices\n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "\n",
        "    # Create a validation set (10% of training data)\n",
        "    val_size = int(0.1 * X_train.shape[0])\n",
        "    X_val = X_train[-val_size:]\n",
        "    y_val = y_train[-val_size:]\n",
        "    X_train = X_train[:-val_size]\n",
        "    y_train = y_train[:-val_size]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Print updated shapes\n",
        "print(\"Training data shape after preprocessing:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f8bb96",
      "metadata": {
        "id": "69f8bb96"
      },
      "source": [
        "### Let's do a quick visualization of sample images (to also ensure we still have the correct shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3efbcbda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3efbcbda",
        "outputId": "25e73d74-3e38-4e14-bcf2-3c0f4d5dd5af"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train[i])\n",
        "    plt.xlabel(label_names[np.argmax(y_train[i])])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee7839c",
      "metadata": {
        "id": "dee7839c"
      },
      "source": [
        "### Let's define our CNN model (architect)\n",
        "-\n",
        "-\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd67c1c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bd67c1c4",
        "outputId": "be74cbca-7576-4264-c557-184153310de3"
      },
      "outputs": [],
      "source": [
        "# Helper function before your create_cnn_model function\n",
        "def residual_block(x, filters, use_projection=False):\n",
        "    \"\"\"Create a residual block with skip connection\"\"\"\n",
        "    shortcut = x\n",
        "    \n",
        "    # First convolution\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    \n",
        "    # Second convolution (no activation yet)\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    # Adjust shortcut dimensions if needed\n",
        "    if use_projection or shortcut.shape[-1] != filters:\n",
        "        shortcut = layers.Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    \n",
        "    # Add skip connection and apply final activation\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "# Modified create_cnn_model function with residual blocks\n",
        "def create_cnn_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    # Use Functional API instead of Sequential for residual connections\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    \n",
        "    # Initial convolution\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    # First residual block (32 filters)\n",
        "    x = residual_block(x, filters=32, use_projection=True)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Second residual block (64 filters)\n",
        "    x = residual_block(x, filters=64, use_projection=True)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Third residual block (128 filters)\n",
        "    x = residual_block(x, filters=128, use_projection=True)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Classifier (same as your simplified version)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create and return the model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = create_cnn_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9009624b",
      "metadata": {
        "id": "9009624b"
      },
      "outputs": [],
      "source": [
        "def apply_data_augmentation():\n",
        "  \"\"\"Apply data augmentation using tf.image (Keras 3.x compatible)\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def augment_image(image, label):\n",
        "    # Only horizontal flip (most conservative augmentation)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    # Very mild brightness adjustment\n",
        "    image = tf.image.random_brightness(image, max_delta=0.05)\n",
        "\n",
        "    # Ensure values stay in [0,1] range\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  # Create tf.data dataset\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "  train_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  train_dataset = train_dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  return train_dataset\n",
        "\n",
        "\n",
        "def apply_mild_data_augmentation():\n",
        "    \"\"\"Apply very conservative data augmentation\"\"\"\n",
        "    datagen = ImageDataGenerator(\n",
        "        horizontal_flip=True,          # Only horizontal flip\n",
        "        width_shift_range=0.05,        # Very small shifts (5%)\n",
        "        height_shift_range=0.05,       # Very small shifts (5%)\n",
        "        rotation_range=5               # Very small rotation (5 degrees)\n",
        "    )\n",
        "\n",
        "    # Fit the augmentation parameters to training data\n",
        "    datagen.fit(X_train)\n",
        "    return datagen\n",
        "\n",
        "# Create the mild augmentation generator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78074c37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78074c37",
        "outputId": "5d4be959-a4ce-4a98-c48b-8a406fb3c493"
      },
      "outputs": [],
      "source": [
        "# Define callbacks for early stopping and model checkpoint\n",
        "from keras.callbacks import EarlyStopping #, ModelCheckpoint\n",
        "k.backend.clear_session()\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True) #,\n",
        "    # ModelCheckpoint('best_cnn_model.keras', monitor='val_accuracy',\n",
        "    #                save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "\n",
        "train_dataset = apply_data_augmentation()\n",
        "#datagen = apply_mild_data_augmentation()\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    #datagen.flow(X_train, y_train, batch_size=64),\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8d5f42",
      "metadata": {
        "id": "dc8d5f42"
      },
      "source": [
        "### It stopped at 24 epochs, it must have not improve for 10 consecutive epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lOzRqysG9TB4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "lOzRqysG9TB4",
        "outputId": "407414ae-ba1e-48c4-cb53-5337ac0411c3"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "def plot_training_history(history):\n",
        "    # Plot accuracy\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0b80b8",
      "metadata": {
        "id": "ad0b80b8"
      },
      "source": [
        "### The CNN model shows:\n",
        "\n",
        "- Good Learning: Training accuracy reached ~94%, validation ~84-85%\n",
        "- Moderate Overfitting: ~9-10% gap between training and validation metrics\n",
        "- Early Plateau: Most learning occurred in first 10 epochs\n",
        "- Stable Validation: Validation metrics stabilized without deteriorating\n",
        "\n",
        "The curves show a well-functioning model that's starting to memorize training data rather than learning generalizable features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lmUhm_gN-Q_X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmUhm_gN-Q_X",
        "outputId": "ccf8de55-75f6-4b59-fe26-064a9b0163be"
      },
      "outputs": [],
      "source": [
        "# Predict classes for test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=label_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e099a9",
      "metadata": {
        "id": "c0e099a9"
      },
      "source": [
        "### Class Performance\n",
        "\n",
        "- Overall Accuracy: 84.2% on test set\n",
        "- Best Classes: Vehicles (ships 92.1%, automobiles 91.8%)\n",
        "- Struggling Classes: Cats (62.1% correct), birds (75.9%)\n",
        "- Man-made vs Natural: Vehicles (90% F1) outperform animals (80% F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WbJiOPqh_dLa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WbJiOPqh_dLa",
        "outputId": "482c9b2c-82a2-428d-e617-4275bf27fb5f"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dOadeSW___n",
      "metadata": {
        "id": "6dOadeSW___n"
      },
      "source": [
        "### Confusion Matrix patterns:\n",
        "- Cat-Dog Confusion: 159 cats misclassified as dogs (biggest issue)\n",
        "- Vehicle Confusion: Some automobile-truck confusion (expected)\n",
        "- Animal Misclassifications: Widespread confusion among mammals\n",
        "\n",
        "Pattern: Classes with consistent appearances perform best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tzZfJFmP_wjr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tzZfJFmP_wjr",
        "outputId": "0428c258-347a-46c7-b3e0-0382aa1e50bd"
      },
      "outputs": [],
      "source": [
        "# Visualize some predictions\n",
        "def visualize_predictions(X, y_true, y_pred, class_names, num_images=25):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(X[i])\n",
        "\n",
        "        true_label = class_names[y_true[i]]\n",
        "        pred_label = class_names[y_pred[i]]\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "\n",
        "        plt.xlabel(f\"T: {true_label}\\nP: {pred_label}\", color=color)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get a subset of test data\n",
        "sample_indices = np.random.choice(len(X_test), 25, replace=False)\n",
        "visualize_predictions(\n",
        "    X_test[sample_indices],\n",
        "    y_true_classes[sample_indices],\n",
        "    y_pred_classes[sample_indices],\n",
        "    label_names\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('cifar10_cnn_model.keras')\n",
        "print(\"Model saved as 'cifar10_cnn_model.keras'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
