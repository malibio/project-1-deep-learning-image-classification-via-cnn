{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d279c439",
      "metadata": {},
      "source": [
        "### Import the CNN Util and libraries needed\n",
        "We have the util to make it easy to create and try new variations of the CNN model and be consistent with how we're analyzing and evaluating it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abe186c",
      "metadata": {
        "id": "5abe186c"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import cnn_utils\n",
        "from keras import layers, models\n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43599bbb",
      "metadata": {
        "id": "43599bbb"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77831e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77831e4",
        "outputId": "bc8992fe-a6cd-42c3-dca0-909d6150da8e"
      },
      "outputs": [],
      "source": [
        "data_dict = cnn_utils.load_cifar10_from_tar()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ba80d8",
      "metadata": {
        "id": "05ba80d8"
      },
      "source": [
        "### Preporcess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5c3162",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a5c3162",
        "outputId": "b0182a1e-0f19-4930-b507-7d02aad78d4f"
      },
      "outputs": [],
      "source": [
        "data = cnn_utils.preprocess_data(data_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f8bb96",
      "metadata": {
        "id": "69f8bb96"
      },
      "source": [
        "### Let's do a quick visualization of sample images (to also ensure we still have the correct shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3efbcbda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "3efbcbda",
        "outputId": "a1b61866-3bcd-4b11-c969-3dba1624bd36"
      },
      "outputs": [],
      "source": [
        "cnn_utils.visualize_data_samples(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c338efe8",
      "metadata": {},
      "source": [
        "### Data Augmentation\n",
        "\n",
        "Moderate geometric augmentation that applies realistic transformations to training images:\n",
        "- Rotation (±15°), shifting (10% in each direction), and zooming (±10%) simulate natural camera angle and distance variations\n",
        "- Horizontal flipping doubles the dataset by creating mirror images (works well for CIFAR-10 since objects like cars/planes look realistic when flipped)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df6db98",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_augmentation():\n",
        "    return ImageDataGenerator(\n",
        "        rotation_range=20,           # Increased from 15\n",
        "        width_shift_range=0.15,      # Increased from 0.1\n",
        "        height_shift_range=0.15,     # Increased from 0.1\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.15,             # Increased from 0.1\n",
        "        brightness_range=[0.8, 1.2], # New: brightness variation\n",
        "        channel_shift_range=0.1,     # New: color variation\n",
        "        fill_mode='nearest'          # Better edge handling\n",
        "    )\n",
        "\n",
        "augmentation = create_augmentation()\n",
        "augmentation.fit(data['X_train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee7839c",
      "metadata": {
        "id": "dee7839c"
      },
      "source": [
        "### Let's define our CNN model (architecture)\n",
        "Deeper, more sophisticated architecture for higher accuracy\n",
        "Structure:\n",
        "- 3 convolutional blocks (64→128→256 filters)\n",
        "- BatchNormalization after each conv layer\n",
        "- Progressive dropout (0.3→0.4→0.5)\n",
        "- Large dense layer (512 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd67c1c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bd67c1c4",
        "outputId": "c408ca46-effe-41ca-d13e-fd497989b169"
      },
      "outputs": [],
      "source": [
        "def create_cnn_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Block 1 - Enhanced with L2 regularization\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001), input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.25))  # Reduced from 0.3\n",
        "    \n",
        "    # Block 2 - With Spatial Dropout\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.SpatialDropout2D(0.25))  # Changed to Spatial Dropout\n",
        "    \n",
        "    # Block 3 - Triple convolutions for deeper feature extraction\n",
        "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(256, (1, 1), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))  # New: 1x1 conv for channel mixing\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.SpatialDropout2D(0.4))\n",
        "    \n",
        "    # Block 4 - Additional block for deeper features\n",
        "    model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu', \n",
        "                           kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    \n",
        "    # Global Average Pooling instead of Flatten (more efficient)\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    \n",
        "    # Enhanced classifier with residual-like connection\n",
        "    model.add(layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b733efd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom callbacks for better training\n",
        "def get_enhanced_callbacks():\n",
        "    return [\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss', \n",
        "            patience=15, \n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "424ab9d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_cnn_model()\n",
        "model.compile(Adam(learning_rate=0.001, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "cnn_utils.print_model_summary(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14f7818",
      "metadata": {},
      "source": [
        "### Now let's train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78074c37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78074c37",
        "outputId": "fea153e9-e4bd-4d8c-bb70-b4ee9f3380fb"
      },
      "outputs": [],
      "source": [
        "history = cnn_utils.train_model(\n",
        "    model, \n",
        "    data, \n",
        "    augmentation=augmentation,\n",
        "    epochs=80,  # Increased epochs\n",
        "    batch_size=32,  # Smaller batch size for better gradients\n",
        "    callbacks=get_enhanced_callbacks()\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01069617",
      "metadata": {},
      "source": [
        "### Let's show the evaluation result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a2a80e",
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_utils.evaluate_model(model, data, history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
