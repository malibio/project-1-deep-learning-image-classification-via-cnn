{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a680d824",
      "metadata": {
        "id": "a680d824"
      },
      "source": [
        "### Make the necessary imports (libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abe186c",
      "metadata": {
        "id": "5abe186c"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras import layers, models, optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os\n",
        "import time\n",
        "import tarfile\n",
        "import pickle\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43599bbb",
      "metadata": {
        "id": "43599bbb"
      },
      "source": [
        "### Load the data from a tar file (using pickle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77831e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77831e4",
        "outputId": "75e9cb81-f978-405b-a920-72b8456febc0"
      },
      "outputs": [],
      "source": [
        "# If you're loading CIFAR-10 from a tar file\n",
        "def load_pickle_from_tar(tar_path, pickle_path):\n",
        "    with tarfile.open('cifar-10-python.tar') as tar:\n",
        "        member = tar.getmember(pickle_path)\n",
        "        f = tar.extractfile(member)\n",
        "        data_dict = pickle.load(f, encoding='bytes')\n",
        "    return data_dict\n",
        "\n",
        "# Set your tar_path to the file in the same working folder\n",
        "tar_path = \"cifar-10-python.tar\"  # File in the same working directory\n",
        "\n",
        "# Load training data\n",
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "print(\"Loading training data...\")\n",
        "# The path structure below is based on the standard CIFAR-10 distribution\n",
        "for i in range(1, 6):\n",
        "    batch_path = f'cifar-10-batches-py/data_batch_{i}'\n",
        "    print(f\"Loading batch {i}...\")\n",
        "    batch_dict = load_pickle_from_tar(tar_path, batch_path)\n",
        "    train_data.append(batch_dict[b'data'])\n",
        "    train_labels.extend(batch_dict[b'labels'])\n",
        "\n",
        "train_data = np.vstack(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ba80d8",
      "metadata": {
        "id": "05ba80d8"
      },
      "source": [
        "### Load the training/test data set and label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5c3162",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a5c3162",
        "outputId": "99cb3e37-3d24-43ba-da3f-65a4c2501fba"
      },
      "outputs": [],
      "source": [
        "print(\"Loading test data...\")\n",
        "test_batch_path = 'cifar-10-batches-py/test_batch'\n",
        "test_dict = load_pickle_from_tar(tar_path, test_batch_path)\n",
        "test_data = test_dict[b'data']\n",
        "test_labels = test_dict[b'labels']\n",
        "\n",
        "# Load label names\n",
        "print(\"Loading label names...\")\n",
        "meta_path = 'cifar-10-batches-py/batches.meta'\n",
        "meta_dict = load_pickle_from_tar(tar_path, meta_path)\n",
        "label_names = [label.decode('utf-8') for label in meta_dict[b'label_names']]\n",
        "\n",
        "# Print basic info about the data\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(f\"Label names: {label_names}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b437380",
      "metadata": {
        "id": "2b437380"
      },
      "source": [
        "### Reshape the data to match the expected input format for CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e9b1ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25e9b1ad",
        "outputId": "0d9d38c6-70ac-49bc-e414-96718f74c65c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Each image is 32x32 pixels with 3 color channels (RGB)\n",
        "X_train = train_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reshape to (N, 32, 32, 3)\n",
        "X_test = test_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reshape to (N, 32, 32, 3)\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# Print updated shapes\n",
        "print(\"Training data shape after reshaping:\", X_train.shape)\n",
        "print(\"Test data shape after reshaping:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f03a3395",
      "metadata": {
        "id": "f03a3395"
      },
      "source": [
        "### Conduct preprocessing of the data:\n",
        "- Normalization (from 255 to 0/1)\n",
        "- Convert class vectors to binary class matices (via one-hot encoding)\n",
        "- Create validation data set (of 10% of training data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80310560",
      "metadata": {
        "id": "80310560"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(X_train: np.ndarray, y_train: np.ndarray,\n",
        "                    X_test: np.ndarray, y_test: np.ndarray):\n",
        "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "    y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "\n",
        "    val_size = int(0.1 * X_train.shape[0])\n",
        "    return (X_train[:-val_size], y_train[:-val_size],\n",
        "            X_train[-val_size:], y_train[-val_size:],\n",
        "            X_test, y_test)\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f8bb96",
      "metadata": {
        "id": "69f8bb96"
      },
      "source": [
        "### Let's do a quick visualization of sample images (to also ensure we still have the correct shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3efbcbda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3efbcbda",
        "outputId": "2c822662-0ebd-436f-bb5a-8898890a0d6e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train[i])\n",
        "    plt.xlabel(label_names[np.argmax(y_train[i])])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970c8aaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d1d830",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_cnn_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.4))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Dense layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc34af2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=64),\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dff979e",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_training_history(history)\n",
        "\n",
        "test_loss, test_acc = deep_custom_model.evaluate(X_test, y_test)\n",
        "print(f\"ðŸŽ¯ Final Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lOzRqysG9TB4",
      "metadata": {
        "id": "lOzRqysG9TB4"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "def plot_training_history(history):\n",
        "    # Plot accuracy\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lmUhm_gN-Q_X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmUhm_gN-Q_X",
        "outputId": "fc9804dd-ea23-4fea-ad74-5f3fb8d57142"
      },
      "outputs": [],
      "source": [
        "# Predict classes for test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=label_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WbJiOPqh_dLa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WbJiOPqh_dLa",
        "outputId": "6964e60e-1ef8-4cd9-fdd9-f20056d8f2d9"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dOadeSW___n",
      "metadata": {
        "id": "6dOadeSW___n"
      },
      "source": [
        "### Confusion Matrix patterns:\n",
        "- Cat-Dog Confusion: 159 cats misclassified as dogs (biggest issue)\n",
        "- Vehicle Confusion: Some automobile-truck confusion (expected)\n",
        "- Animal Misclassifications: Widespread confusion among mammals\n",
        "\n",
        "Pattern: Classes with consistent appearances perform best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tzZfJFmP_wjr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tzZfJFmP_wjr",
        "outputId": "6e41c5dc-6098-4129-9fef-d8eb690a9e52"
      },
      "outputs": [],
      "source": [
        "# Visualize some predictions\n",
        "def visualize_predictions(X, y_true, y_pred, class_names, num_images=25):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(X[i])\n",
        "\n",
        "        true_label = class_names[y_true[i]]\n",
        "        pred_label = class_names[y_pred[i]]\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "\n",
        "        plt.xlabel(f\"T: {true_label}\\nP: {pred_label}\", color=color)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get a subset of test data\n",
        "sample_indices = np.random.choice(len(X_test), 25, replace=False)\n",
        "visualize_predictions(\n",
        "    X_test[sample_indices],\n",
        "    y_true_classes[sample_indices],\n",
        "    y_pred_classes[sample_indices],\n",
        "    label_names\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('cifar10_cnn_model.keras')\n",
        "print(\"Model saved as 'cifar10_cnn_model.h5'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
